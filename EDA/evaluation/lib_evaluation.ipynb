{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6432e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import recsys_metrics as rm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c39aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'ml_100k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c409630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c258d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.10318133616118777, 'recall': 0.2519216330858957, 'mean_average_precision': 0.2202162248144221, 'mean_reciprocal_rank': 0.3353185577942736, 'hit_rate': 0.9692470837751855, 'normalized_dcg': 0.2033918345705197}\n"
     ]
    }
   ],
   "source": [
    "def user_to_tensors(user_group, user_positives):\n",
    "    user_id = user_group.name\n",
    "    positives = set(user_positives.get(user_id, []))\n",
    "    \n",
    "    sorted_group = user_group.sort_values('score', ascending=False)\n",
    "    items = sorted_group['item'].values\n",
    "    scores = sorted_group['score'].values\n",
    "    \n",
    "    target = torch.tensor(\n",
    "        [1 if item in positives else 0 for item in items],\n",
    "        dtype=torch.float32\n",
    "    ).unsqueeze(0)\n",
    "    \n",
    "    # Create preds tensor\n",
    "    preds = torch.tensor(scores, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    return preds, target\n",
    "\n",
    "\n",
    "def compute_rank_report(pred_df, user_positives, k=10):\n",
    "\n",
    "    results = pred_df.groupby('user').apply(\n",
    "        lambda g: pd.Series(rm.rank_report(\n",
    "            preds=user_to_tensors(g, user_positives)[0],\n",
    "            target=user_to_tensors(g, user_positives)[1],\n",
    "            k=k\n",
    "        )),\n",
    "        meta={metric: 'f8' for metric in ['precision', 'recall', 'mean_average_precision', 'mean_reciprocal_rank', 'hit_rate', 'normalized_dcg']}\n",
    "    ).compute()\n",
    "    \n",
    "\n",
    "    return results.mean().to_dict()\n",
    "\n",
    "pred_df = dd.read_csv(path + 'ranking.tsv', sep='\\t', \n",
    "                     names=['user', 'item', 'score', 'pred_label'])\n",
    "\n",
    "test =  pd.read_csv(path + 'test.tsv', sep='\\t', \n",
    "                names=['user', 'item', 'label','timestamp'])\n",
    "\n",
    "user_positives = test.groupby('user')['item'].apply(list).to_dict()\n",
    "\n",
    "metrics = compute_rank_report(pred_df, user_positives, k=10)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
